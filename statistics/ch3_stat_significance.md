# 데이터 과학을 위한 통계 3장 : 통계적 실험과 유의성 검정

전통적인 실험설계에 대해 알아보고 데이터 과학에도 적용되는 몇몇 어려움에 대해 논의해보자.

통계적 유의성, t 검정, p값 등은 **통계적 추론**이라는 파이프라인 속에 있다. 이 과정은 *가격 A가 기존 가격 B보다 수익성이 높다* 라는 식의 가설을 세우는 것에서 출발한다. 가설을 검정하고 원하는 결론을 도출할 수 있도록 실험을 설계한다. 그리고 데이터를 수집하고 분석하여 결론을 도출한다.

**추론 (inference)** 이라는 용어는 제한된 데이터로 이루어진 실험의 결과를 더 큰 대상 또는 모집단에 적용하고자 하는 의도를 나타낸다.

## (1) A/B 테스트

A/B 테스트는 두 처리 방법, 제품 , 혹은 절차 중 어느 쪽이 다른 쪽보다 더 우월하다는 것을 입증하기 위해 실험군을 두 그룹으로 나누어 진행하는 실험이다. 종종 두 가지 그룹 중 하나는 기존 방법이거나 아무런 처리를 하지 않는 **대조군** 으로 설정된다. 새로운 처리법을 적용하는 것이 대조군보다 낫다는 것이 일반적인 가설이 된다.

- 이상적인 경우 피험자는 **무작위** 로 A, B군 중 하나에 할당된다
- 그룹 간 비교에 사용하는 검정통계량 또는 측정 지표에 주의해야 한다 (이진 변수, 연속형, 횟수)
- 여러 가지 정보를 수집할 수 있지만, 사용하고자 하는 지표 또는 검정통계량을 사전에 미리 정해놓아야 한다.
    - 실험 후에 지표를 선택한다면 연구자 편향에 빠질 수 있다.

### 대조군은 왜 필요할까?

대조군이 없다면 어떤 차이가 변경사항 때문인지 우연히 발생한 것인지 확신할 수 없다.

## (2) 가설검정

가설검정 혹은 유의성 검정은 관찰된 효과가 우연에 의한 것인지 여부를 알아내기 위한 기법이다.
사람들은 예외적인 사건을 예상하지 못하거나, 무작위로 발생한 사건을 의미있는 패턴으로 오해하는 경향이 있다.
통계적 가설 검정은 연구자가 우연히 일어난 일에 속지 않도록 보호하기 위해 개발되었다.

### 귀무가설

가설검정에서는 실험을 통해 얻은 그룹 간의 차이가 랜덤으로 발생할 수 있는 합리적인 수준보다 더 극단적으로 다르다는 증거를 요구한다.
이 과정에서 그룹 간의 차이는 우연에 의한 결과라는 것을 기본 가정으로 하는데, 이것을 **귀무가설** 이라고 한다.

### 대립가설

귀무가설과 대립하는 가설을 말한다. 몇 가지 예시를 살펴보자.

```
- 귀무가설 : A와 B 그룹의 평균에는 차이가 없다
- 대립가설 : A는 B와 다르다

- 귀무가설 : A는 B보다 작거나 같다
- 대립가설 : A는 B보다 크다

- 귀무가설 : B는 A보다 3% 크지 않다
- 대립가설 : B는 A보다 3% 크다
```

### 일원/이원 가설검정

방향성을 고려한 대립가설이 필요할 때도 있다 ( B가 A보다 크다 ). 이 경우에는 일원 가설검정 (한쪽 꼬리) 을 사용한다.
어느 쪽으로도 속지 않도록 가설검정을 수행하려면 대립가설은 양방향이 된다 ( B는 A와 다르다 ). 이 경우에는 이원 가설검정 (양쪽 꼬리) 을 사용한다.

## (3) 재표본추출

**재표본추출**이란 랜덤한 변동성을 알아보자는 일반적인 목표를 가지고, 관찰된 데이터의 값에서 표본을 반복적으로 추출하는 것을 의미한다.
또한 일부 머신러닝 모델의 정확성을 평가하고 향상시키는 데에도 적용할 수 있다.

재표본추출에는 부트스트랩과 순열검정이라는 두 가지 주요 유형이 있다. 여기서는 순열검정에 대해 알아보려고 한다.

* 부트스트랩 : 추정의 신뢰성을 평가
* 순열검정 : 두 개 이상의 그룹과 관련된 가설을 검증

### 순열검정

순열검정에서는 여러 그룹들의 결과를 하나로 합친다.
이것은 그룹들에 적용된 처리의 결과가 다르지 않다는 귀무가설을 구체화한 것이다.
그 후 결합된 집합에서 무작위로 그룹을 뽑아 가설을 검정하고 서로 얼마나 다른지 확인한다.
구체적인 절차는 다음과 같다.

1. 여러 그룹의 결과를 단일 데이터 집합으로 결합한다
2. 결합된 데이터를 잘 섞은 후, 그룹 A와 동일한 크기의 표본을 무작위로 비복원 추출한다
3. 나머지 데이터에서 그룹 B와 동일한 크기의 샘플을 무작위로 비복원 추출한다
4. 다른 그룹이 더 있다면 동일한 작업을 수행한다
5. 새로 추출한 재표본에서 통계량 또는 추정치를 다시 계산하고 기록한다
6. 앞선 단계를 R번 반복하고 검정통계량의 순열 분포를 얻는다

이제 실험을 통해 얻은 수치를 순열 과정에서 얻은 집합에서의 수치와 비교한다.
관찰된 값이 재표본을 통해 얻은 값들의 분포와 비교했을 때 겹치는 구간에 있다면, 우연히 일어날 수 있는 범위 안에 있다는 말이다.
하지만 그렇지 않을 경우 우연 때문이 아니라고 결론 내릴 수 있고, 이것을 **통계적으로 유의미하다** 고 표현한다.

### 전체 및 부트스트랩 순열검정

앞서 살펴본 랜덤 셔플링 절차를 임의순열검정 (Random Permutation Test) 또는 임의화검정 (Randomization Test) 이라고 부른다.
이외에도 몇 가지 변종이 있다.

- **전체순열검정** (exhaustive permutation test)
    - 데이터를 무작위로 섞는 대신 실제로 발생할 수 있는 모든 가능한 조합을 찾는다
    - 샘플 크기가 비교적 작을 때만 실용적이다
    - 임의순열검정의 결과는 셔플링을 많이 반복할수록 전체순열검정의 결과와 비슷해진다
    - *유의미하다*같은 애매한 결론이 아닌 더 정확한 결론을 보장하기 때문에 정확검정 (exact test) 라고도 한다
- **부트스트랩 순열검정** (bootstrap permutation test)
    - 추출하는 과정을 **복원추출로 진행** 한다

### 순열검정의 장점

- 상대적으로 코딩하고, 해석하고, 설명하기 쉽다
- 데이터의 형태가 다양해도 된다
- 샘플 크기가 다양해도 된다
- 데이터가 정규분포를 따를 필요도 없다

## (4) 통계적 유의성과 p값

통계적 유의성이란, 실험 결과가 우연히 일어난 것인지 우연히 일어날 수 없는 극단적인 상황인지 판단하는 방법이다. 결과가 우연히 벌어질 수 있는 변동성의 바깥에 존재한다면 통계적으로 유의하다고 말한다.

### p 값

P값은 확률모형이 관측된 결과보다 더 극단적인 결과를 생산하는 비율을 의미한다. 순열검정을 통해 얻은 결과 중에서, 관찰된 차이와 같거나 더 큰 차이를 보이는 경우의 비울로 p값을 추정할 수 있다.

### 유의수준

연구자들은 어떤 결과가 우연히 발생한 것인지 결정하기 위해 어떤 임계값을 미리 지정해두는 편을 선호한다. 이러한 임계값을 보통 유의수준 (알파) 라고 한다. 5%, 1%가 많이 사용된다. 올바른 임계값을 보장하는 프로세스는 없다.

### p값의 의미

우리가 p값을 통해 전달하고자 하는 의미는 다음과 같다.

> 결과가 우연히 발생할 확률

따라서 우리는 더 낮은 p값이 나와서 가설이 맞다는 것을 증명하길 바란다. 하지만 실제로 p값이 나타내는 것은 다음과 같다.

> 랜덤 모형이 주어졌을 때, 그 결과가 관찰된 결과보다 더 극단적일 확률

p값이 유의미하다고 해서 바로 증거가 되는 것은 아니다. p값의 진짜 의미를 이해하면 *통계적으로  유의미하다* 라는 결론에 대한 논리적인 뒷받침이 다소 약하다는 것을 알게 된다.

2016년 3월 미국통계협회(ASA)는 내부 심의를 거쳐, p값의 사용에 대한 경고를 촉구하는 성명서를 통해 아래 6가지 원착을 강조했다.

1. p값은 이 데이터가 특정 통계 모형과 얼마나 상반되는지 나타낼 수 있다
2. p값은 연구 가설이 사실일 확률이나, 데이터가 랜덤하게 생성되었을 확률을 측정하는 것이 아니다
3. 과학적 결론, 비즈니스, 정책 결정은 p값이 특정 임계값을 통과하는지 여부를 기준으로 해서는 안된다
4. 적절한 추론을 위해서는 완전한 보고와 투명성이 요구된다
5. p값 또는 통계적 유의성은 효과의 크기나 결과의 중요성을 의미하지 않는다
6. p값 그 자채는 모델이나 가설에 대한 증거를 측정하기 좋은 지표가 아니다

### 데이터 과학과 p값

p값의 가치에 대한 논쟁은 다소 학문적이다. 데이터 과학자에게 p값은 모형의 결과가 일반적인 랜덤 범위 내에 있는지를 알고 싶을 때 유용한 측정 지표다. p값은 어떤 결정에 관련된 정보의 일부일 뿐이다.

## (5) t 검정

모든 유의성 검정은 관심 있는 효과를 측정하기 위한 **검정통계량** 을 지정하고, 관찰된 효과가 정상적인 랜덤 변이의 범위 내에 있는지 여부를 판단하는데 도움을 준다.

통계학자들은 순열 분포에 대한 좋은 근사가 고셋의 t 분포에 기초한 t 검정이라는 것을 발견했다. 이는 데이터가 수치형인 일반적인 2표본 비교(A/B테스트)에 주로 사용한다.

## (6) 다중 검정

통계학에서는 다음과 같은 말이 있다.

> 데이터를 충분히 오래 고문하다 보면 언젠간 뭐든 털어놓을 것이다.

다양한 관점으로 데이터를 보고 충분한 질문을 던지다 보면 거의 항상 통계적으로 유의미한 결과가 나오게 된다. 예를 들어 20개의 예측변수와 1개의 결과변수가 모두 임의로 생성되었다고 하자. 유의수준 0.05에서 20번의 유의성 검정을 수행하면 적어도 하나의 예측변수에서 통계적으로 유의미한 결과를 (실수로) 초래할 가능성이 있다. 이것을 **1종 오류** 라고 한다. 정확하게 검정할 확률이 0.95 이므로, 20번 모두 무의미하다고 올바른 검정 결과가 나올 확률을 구해보면 `0.95^20 = 0.358` 이다. 적어도 하나의 예측값이 유의미하다는 결과가 나올 확률은 1 - 0.358 = **0.642** 이다.

이 문제는 데이터 마이닝의 **오버피팅** 문제와 관련이 있다. 추가하는 변수가 많아지거나 더 많은 모델을 사용할수록 우연에 의해 유의미한 것으로 나타날 확률이 높아진다.

- 지도 학습에서는 이런 위험을 낮추기 위해, 홀드아웃 세트를 사용해서 이전에 보지 못했던 데이터를 통해 모델을 평가한다
- 통계학에서는 특정 상황에서 이러한 문제를 다루기 위한 방법이 몇 가지 있다
    - 여러 처리 그룹간의 결과를 비교할 경우, 여러 질문을 할 수 있다
        - A와 B가 서로 다른가?
        - B와 C가 서로 다른가?
        - A와 C가 서로 다른가?
    - 통계적 유의성에 대한 기준을 더 엄격하게 설정함으로써 보완할 수도 있다
        - 유의수준 / 검정횟수 을 계산하여 더 작은 alpha 값을 적용한다 (본페로니 수정)

하지만 다중검정 문제는 이렇게 잘 구조화된 경우가 아니라, 데이터를 고문한다는 말이 나올 정도로 반복적으로 데이터를 샅샅이 훑는 현상과 관련이 있다. 더 많은 연구가 반드시 더 나은 연구를 의미하는 것은 아니다.

이러한 문제에 대한 데이터 과학자들의 결론은 다음과 같다.

- 예측 모델링의 경우 교차 타당성검사와 홀드아웃 표본 사용을 통해, 우연히 발생한 것을 유효한 것처럼 보이도록 모형이 잘못 생성되지 않도록 한다
- 미리 분류되어 있는 홀드아웃 표본이 없는 다른 절차의 경우, 다음 사항에 의존해야 한다
    - 데이터를 더 여러 번 사용하고 조작할수록 우연이 더 큰 역할을 할 수 있다는 것을 인식한다
    - 재표본추출과 시뮬레이션 결과를 사용하여 무작위 모델의 기준값과 관찰된 결과를 비교한다

## (7) 자유도

자유도는 표본 데이터에서 계산된 통계량에 적용되며, 변화가 가능한 값들의 개수를 나타낸다.
예를 들면 10개의 값으로 이뤄진 표본에서 평균과 9개 값을 알고 있다면, 마지막 10번째 값을 알 수 있다.
따라서 여기서는 9개의 값만 변화할 수 있다.

표본을 통해 모집단의 분산을 추정하고자 할 때 분모에 n 대신 n-1을 사용해야 추정값에 편향이 발생하지 않는다.
그런데 이것이 데이터 과학에서도 중요할까?

- 유의성 검정에서는 그렇지 않다
    - 데이터의 크기가 대개 충분히 크기 때문에, 분모가 n인지 n-1인지 크게 중요하지 않은 경우가 많다
- 회귀에서 요인변수를 사용할 때는 중요하다
    - 범주형 변수를 dummy 변수로 바꾸는 경우!
    - 요일별로 더미 변수를 만든다면 자유도는 6이어야 한다

## (8) 분산분석

여러 그룹, 예를 들면 A, B, C, D 그룹의 수치 데이터를 서로 비교한다고 가정해보자. 여러 그룹 간에 통계적으로 유의미한 차이가 있는지를 검정하는 통계적 절차를 **분산분석(ANOVA)** 이라고 한다. A와 B를 비교하고 B와 C를 비교하는 등 가능한 모든 조합을 비교한다면 우연히 일어난 일에 속을 가능성이 높아진다. 대신 모든 그룹이 동일한 특성을 보이는지, 또는 그룹 간의 차이가 우연히 발생한 것인지 질문할 수 있다.

ANOVA의 토대가 되는 재표본추출 과정을 살펴보자.

1. 모든 데이터를 한 상자에 모은다
2. 5개의 값을 갖는 4개의 재표본을 섞어서 추출한다
3. 각 그룹의 평균을 기록한다
4. 네 그룹 평균 사이의 분산을 기록한다
5. 2,3,4단계를 여러 번 반복한다

재표집된 분산이 관찰된 변화를 초과한 정도가 바로 p값이 된다.

### F 통계량

F 통계량은 잔차 오차로 인한 분산과 그룹 평균의 분산에 대한 비율을 기초로 한다. 이 비율이 높을수록 통계적으로 유의미하다. 데이터가 정규분포를 따를 경우, 해당 통계량은 특정 분포를 따르게 되어 있기 때문에 이를 바탕으로 p값을 계산할 수 있다.
