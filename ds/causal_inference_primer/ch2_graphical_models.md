# Ch2. Graphical Models and their applications

## 2.1 Connecting Models to Data

1장의 내용을 통해 데이터의 독립성 패턴을 그래피컬 모형을 통해 표현할 수 있다는 것을 확인했다.
구조방정식으로 나타냈을 때의 가중치 값이나 오차의 분포같은 것들을 몰라도 가능하다.
또한, 데이터의 독립성 패턴을 관찰함으로써 우리의 가설이 맞는지 확인할 수 있다.
최종적으로 3장에서는 그래프 구조와 데이터의 결합을 통해, 변수들의 개입으로 인한 영향을 실제로 테스트해보지 않더라도 정량적으로 예측할 수 있다.

## 2.2 Chains and Forks

그동안 우리는 인과 모형을 데이터의 "인과적인 스토리" 로 표현했다.
또 다른 방식으로는 **데이터가 생성되는 메커니즘** 으로 이해할 수 있다.

만약 고등학교 학생들의 수학 성적에 대한 완벽한 인과 모형을 가지고 있고, 외부에서 개입할만한 변수들도 모두 알 수 있다면, 이론적으로는 모든 개개인의 성적을 예상해 볼 수 있다.
물론 이렇게 할 수 있으려면 성적에 영향을 미치는 모든 요인을 알고 있어야 하기 때문에 비현실적인 일이다.
대부분의 경우, 우리는 그 정도로 상세한 정보를 알고 있지 않다.
대신에 외부 변수들에 대한 확률 분포를 사용할 수 있다.
이를 통해 전체 학생들과 특정 그룹의 학생들에 대해서 성적의 분포를 구할 수 있을 것이다.

이러한 상황에서 그래피컬 모형만 가지고 있다고 가정해보자.
그러면 어떤 변수들이 서로 관련이 있는지는 알 수 있지만, 얼마나 강하게 연결되어 있는지는 알 수 없다.
하지만 그런 제한적인 정보로도, 우리는 모형에 의해 생성된 데이터에 대해 많은 것들을 알 수 있다.
어떤 변수들이 서로 독립적이고, 어떤 변수들이 특정 조건 하에 서로 독립인지 학습할 수 있다.

동일한 그래피컬 모형을 가지는 세 가지 SCM에 대해서 살펴보자.

1. 고등학교 기금의 양 (X) , 평균 SAT 점수 (Y) , 대학 진학률 (Z)
2. 스위치의 상태 (X) , 연결된 전기 회로의 상태 (Y) , 전구의 상태 (Z)
3. 근무시간 (X) , 훈련시간 (Y) , 경주 성적 (Z)

세 모형 모두 외생변수 Ux, Uy, Uz 가 존재한다.
이 변수들은 모형 내부 변수들 간의 관계를 변화시킬 수 있는 알려지지 않은 효과를 의미한다.
그리고 세 모형은 아래와 같이 동일한 형태의 그래피컬 모형을 가진다.

```
X → Y → Z
↑   ↑   ↑
Ux  Uy  Uz
```

그래피컬 모형을 통해 어떤 변수들이 서로 독립인지 아닌지 파악할 수 있다.

1. Z와 Y는 독립이 아닐 것이다 ( `P(Z=z | Y=y) != P(Z=z)` )
2. Y와 X는 독립이 아닐 것이다 ( `P(Y=y | X=x) != P(Y=y)` )
3. Z와 X는 독립이 아닐 것이다 ( `P(Z=z | X=x) != P(Z=z)` )
4. Z와 X는 Y값이 결정되어 있을 때 서로 독립이다 ( `P(Z=z | X=x, Y=y) != P(Z=z | Y=y)` )

왜 이러한 관계가 구성되는지 알기 위해서는 그래피컬 모형을 자세히 살펴보아야 한다. 우선 직접 edge를 통해 연결된 두 변수는 서로 종속되어 있다. `A -> B` 의 관계에서 A 변수는 B 변수에 영향을 미친다. 다시 말해 **B 변수는 A 변수의 값에 의존한다.** 따라서 X와 Y는 서로 의존 관계에 있고, Y와 Z도 서로 의존 관계에 있다. 그렇다면 X의 값이 변했을 때 Y에도 영향을 미치고, 이것이 Z에도 영향을 미치므로 X와 Z도 의존 관계에 있다고 볼 수 있다.

그런데 위와 같은 조건인데도 X와 Z가 의존관계가 아닌 경우가 존재할 수 있다.

```
V = {X, Y, Z}, U = {Ux, Uy, Uz}, F = {Fx, Fy, Fz}

Fx : X = Ux

Fy : Y = {
  Y = a IF X = 1 AND Uy = 1
  Y = b IF X = 2 AND Uy = 1
  Y = c IF Uy = 2
}

Fy : Z = {
  Z = i IF Y = c OR Uz = 1
  Z = j IF Uz = 2
}
```

위와 같은 경우에는, Uy와 Uz의 값과 상관없이 X는 Z에 영향을 주지 못한다.
X의 값은 Y값이 a나 b가 되는데는 영향을 미칠 수 있지만, Z의 값은 Y가 c인지 아닌지에만 영향을 받기 때문이다.
따라서 이 모형에서 X와 Z는 독립적으로 변한다.
이러한 경우를 intransitive case 라고 한다.
하지만 이런 경우는 많지 않다. 대부분의 경우는 X가 Z에 영향을 미칠 수 있다.

이제까지 살펴본 변수 관계, 즉 세 개의 노드와 두 개의 엣지로 구성되어 있고 각 노드가 `X → Y → Z` 순서로 나란히 연결되어 있는 관계를 **chain** 이라고 한다.
어떤 두 변수가 중간 변수와 함께 chain으로만 연결되어 있다면, X와 Y는 중간변수의 값이 결정되어 있을 때 조건부로 독립이다.
이러한 관계는 변수들이 어떤 함수로 연결되어 있든 성립한다.
따라서 다음과 같은 법칙을 정의해 볼 수 있다.

> **Rule 1 : Conditional Independence in Chains**
>
> 두 변수 X와 Y 사이에 단 하나의 단방향 path만 있다면, X와 Y는 Z의 값이 주어졌을 때 조건부 독립이다.
